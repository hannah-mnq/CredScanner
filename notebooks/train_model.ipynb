{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "499d05c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import os \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8466b820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt', download_dir='nltk_data') \n",
    "nltk.data.path.append('./nltk_data') \n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18934b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(str(text))\n",
    "    cleaned = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "    return ' '.join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89377d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_FOLDER = \"../data/fake_news/\"\n",
    "full_df = pd.read_csv(DATA_FOLDER + \"clean_fake_news.csv\")\n",
    "\n",
    "full_df['text'] = full_df['text'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2cde6d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>Majority of people in France now dissatisfied ...</td>\n",
       "      <td>paris reuters french voter dissatisfied emmanu...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 26, 2017</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29808</th>\n",
       "      <td>White SC Cops Sexually Assault Black Couple D...</td>\n",
       "      <td>video published washington post show white pol...</td>\n",
       "      <td>News</td>\n",
       "      <td>April 2, 2016</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29981</th>\n",
       "      <td>Organizers name TV journalists to moderate U.S...</td>\n",
       "      <td>washington reuters journalist nbc abc cnn fox ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>September 2, 2016</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17278</th>\n",
       "      <td>Brother of Marseille attacker arrested in Ital...</td>\n",
       "      <td>rome reuters october story refiled correct nam...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 8, 2017</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21329</th>\n",
       "      <td>Cameroon orders Anglophone region total lockdo...</td>\n",
       "      <td>yaounde reuters cameroon authority friday bann...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 29, 2017</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "2649   Majority of people in France now dissatisfied ...   \n",
       "29808   White SC Cops Sexually Assault Black Couple D...   \n",
       "29981  Organizers name TV journalists to moderate U.S...   \n",
       "17278  Brother of Marseille attacker arrested in Ital...   \n",
       "21329  Cameroon orders Anglophone region total lockdo...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "2649   paris reuters french voter dissatisfied emmanu...     worldnews   \n",
       "29808  video published washington post show white pol...          News   \n",
       "29981  washington reuters journalist nbc abc cnn fox ...  politicsNews   \n",
       "17278  rome reuters october story refiled correct nam...     worldnews   \n",
       "21329  yaounde reuters cameroon authority friday bann...     worldnews   \n",
       "\n",
       "                      date label  \n",
       "2649      August 26, 2017   REAL  \n",
       "29808        April 2, 2016  FAKE  \n",
       "29981   September 2, 2016   REAL  \n",
       "17278     October 8, 2017   REAL  \n",
       "21329  September 29, 2017   REAL  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df, valid_df = train_test_split(full_df, test_size=0.2, stratify=full_df['label'], random_state=42)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "131be944",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts=train_df['text'].tolist()\n",
    "train_labels = train_df['label'].tolist()\n",
    "\n",
    "\n",
    "val_texts = valid_df['text'].tolist()\n",
    "val_labels = valid_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9352fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enoded classes:  ['FAKE' 'REAL']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(['FAKE','REAL'])\n",
    "train_labels_enc = label_encoder.fit_transform(train_labels)\n",
    "val_labels_enc = label_encoder.transform(val_labels)\n",
    "print(\"Enoded classes: \", label_encoder.classes_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df64b3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding in batches: 100%|██████████| 965/965 [51:00<00:00,  3.17s/it]  \n",
      "Encoding in batches: 100%|██████████| 242/242 [11:53<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:25:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9596993650382273\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.96      0.95      0.95      3479\n",
      "        REAL       0.96      0.97      0.96      4238\n",
      "\n",
      "    accuracy                           0.96      7717\n",
      "   macro avg       0.96      0.96      0.96      7717\n",
      "weighted avg       0.96      0.96      0.96      7717\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['..\\\\src\\\\sbert_model.joblib']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def encode_in_batches(sentences, model, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Encoding in batches\"):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        emb = model.encode(batch, show_progress_bar=False)\n",
    "        embeddings.extend(emb)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train = encode_in_batches(train_texts, sbert_model)\n",
    "X_val = encode_in_batches(val_texts, sbert_model)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, train_labels_enc)\n",
    "\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "val_preds = clf.predict(X_val)\n",
    "acc = accuracy_score(val_labels_enc, val_preds)\n",
    "print(\"Validation Accuracy:\", acc)\n",
    "\n",
    "target_names = [str(cls) for cls in label_encoder.classes_]\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(\n",
    "    val_labels_enc, val_preds,\n",
    "    labels=list(range(len(target_names))),\n",
    "    target_names=target_names\n",
    "))\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "save_path = os.path.join(\"..\", \"src\")\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "joblib.dump(clf, os.path.join(save_path, \"classifier_model.joblib\"))\n",
    "joblib.dump(label_encoder, os.path.join(save_path, \"label_encoder.joblib\"))\n",
    "joblib.dump(sbert_model, os.path.join(save_path, \"sbert_model.joblib\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
